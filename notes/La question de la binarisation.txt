La question de la binarisation illustre bien l’évolution des méthodes. Pendant longtemps, la première étape consistait à transformer une image en noir et blanc : soit un pixel est blanc, soit il est noir. Cette simplification rendait plus facile la détection des lettres par les machines, qui pouvaient alors comparer directement des formes typographiques pré-enregistrées. Mais ce passage forcé au noir et blanc avait un coût : perte d’information sur les nuances, et sensibilité accrue aux défauts d’impression ou aux images bruitées. Aujourd’hui, cette étape n’est plus incontournable. Elle reste pratique pour traiter des documents très dégradés — comme certains microfilms — mais les systèmes modernes savent travailler directement avec des images en niveaux de gris ou même en couleur (rouge-vert-bleu). Plus fort encore, certains réseaux apprennent automatiquement à « décider » quels contrastes ou seuils sont pertinents, là où les anciennes méthodes appliquaient une règle fixe.

On comprend ici la bascule entre deux époques de l’OCR. Les anciens systèmes fonctionnaient comme une chaîne d’opérations séparées : on nettoyait l’image, on la binarisait, on comparait chaque forme à une base de motifs connus, puis on s’aidait de dictionnaires pour corriger les erreurs. C’était une sorte de mécanique en plusieurs rouages, où chaque étape pouvait accumuler des approximations. Les systèmes contemporains, eux, reposent sur des modèles neuronaux capables d’apprendre l’ensemble du processus de bout en bout : ils prennent une image brute et produisent directement du texte, en intégrant en interne tout ce qui était autrefois découpé en étapes.

L’OCR est donc passé d’une logique d’artisanat — avec ses règles, ses heuristiques, ses bricolages de segmentation — à une logique d’apprentissage profond, où le réseau s’entraîne sur d’immenses corpus et apprend par lui-même à reconnaître les lettres et les mots, même dans des conditions variées. On peut dire que l’ancien OCR ressemblait à un puzzle dont on assemblait les pièces une à une, tandis que le nouvel OCR agit comme une seule machine qui « devine » d’un seul coup le texte caché dans l’image.

Cette évolution a des conséquences fortes : l’OCR n’est plus seulement un outil technique de reconnaissance de formes, mais une technologie pivot pour la transmission et l’accessibilité des savoirs. Elle s’appuie sur une longue histoire d’expérimentations, et continue de se transformer au rythme des avancées en vision artificielle et en traitement automatique du langage. Dans la société numérique, où la masse de documents numérisés ne cesse de croître, elle demeure une clé essentielle pour rendre ces textes exploitables, interrogeables et transmissibles.
