### Un standard à la croisée de la sphère technique et la sphère sociale : IIIF

C’est dans ce contexte qu’émergent des standards comme le IIIF (International Image Interoperability Framework), né dans les années 2010 sous l’impulsion d’un consortium de grandes bibliothèques (BnF, British Library, Stanford, etc.). IIIF répond à une double exigence, à savoir : uniformiser l’accès aux images numérisées en définissant des API permettant de zoomer, annoter, partager et intégrer les images dans des environnements divers et favoriser l’interopérabilité entre institutions en permettant qu’un même document numérisé à Londres, Paris ou New York puisse être consulté, manipulé et enrichi dans une interface commune.

IIIF illustre bien l’évolution de la numérisation vers la *datafication* : il ne s’agit plus seulement de stocker et montrer des images, mais de les intégrer dans un écosystème où elles deviennent manipulables, annotables, recombinables. Un manuscrit, une affiche ou un numéro du *Journal Officiel* numérisé n’est plus seulement une image : c’est une ressource ouverte, potentiellement enrichie par des métadonnées, des annotations collaboratives ou des algorithmes d’analyse.

### "Le goût de l'archive à l'ère numérique"

La réflexion sur la datafication des corpus ne peut être dissociée du « goût de l’archive » à l’ère numérique. Le terme, mobilisé par le collectif [retrouver les noms exacts], met en évidence un paradoxe : alors que la numérisation promet une accessibilité inédite aux archives, elle en modifie profondément l’expérience sensible. L’historien ne se trouve plus confronté à des boîtes, des liasses ou des volumes, mais à des corpus massifs, fragmentés, médiés par des interfaces, des moteurs de recherche ou des API.

Ce déplacement fait écho à un débat ancien dans l’historiographie française. Dès les années 1960, Chaunu ou Le Roy Ladurie, dans le sillage de l’École des Annales, avaient déjà revendiqué l’importance des archives sérielles — registres de baptêmes, testaments, cadastres, minutes notariales — au détriment des sources narratives ou « événementielles » jugées plus séduisantes. Ils affirmaient que l’histoire pouvait (et devait) se nourrir de ces « archives grises », répétitives, sans attrait esthétique ni émotionnel, mais capables, une fois cumulées et quantifiées, de révéler des structures profondes (démographiques, sociales, économiques). Autrement dit, l’absence de « goût » de ces archives constituait paradoxalement leur force heuristique.

L’ère numérique radicalise ce basculement : ce qui, dans les années 1970, nécessitait des dépouillements manuels interminables et le recours à l’informatique balbutiante, peut désormais être automatisé et amplifié à une échelle inédite. La datafication prolonge l’intuition des Annales en rendant ces fonds sériels interrogeables et manipulables à grande vitesse. Mais elle modifie aussi l’expérience sensible : le « goût » ne réside plus dans l’objet matériel de l’archive, mais dans la découverte de motifs et de régularités rendus visibles par des visualisations, des bases de données ou des modèles.

Ainsi, l’historien se trouve à nouveau confronté à un paradoxe : les archives sérielles, longtemps délaissées pour leur monotonie, acquièrent une nouvelle attractivité dans l’espace numérique, mais au prix d’un changement de régime du sensible. Le risque est alors de réduire l’archive à son seul potentiel calculable. Le défi, aujourd’hui comme hier, est de concilier la puissance cumulative de ces données avec la vigilance critique nécessaire à l’interprétation de leurs conditions de production.
